{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phils Section Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database credentials\n",
    "from config import username, password\n",
    "\n",
    "# Used for making database connection.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "# Used to abstract classes into tables.\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "# Used to declare column types.\n",
    "from sqlalchemy import Column, Integer, String, Float, ForeignKey\n",
    "\n",
    "# Used to load pandas dataframe into sql.\n",
    "import d6tstack.utils\n",
    "import time\n",
    "\n",
    "# Ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Used for reading, writing to, and zipping files/folders.\n",
    "from pathlib import Path\n",
    "import os, zipfile\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "COMMODITY_TRADE_CSV = os.path.join(\".\", \"Resources\", \"commodity_trade_statistics_data.csv\")\n",
    "FINANCIAL_AID_CSV =  os.path.join(\".\", \"Resources\", \"june-9-data-csv-1.csv\")\n",
    "DB_NAME = \"trade_db\"\n",
    "COMMODITY_TABLE = \"commodity\"\n",
    "COMMODITY_CATEGORY_TABLE = \"commodity_category\"\n",
    "COMMODITY_CODE_TABLE = \"commodity_code\"\n",
    "COUNTRY_TABLE = \"country\"\n",
    "cfg_uri_psql = f\"postgresql+psycopg2://{username}:{password}@localhost/{DB_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip data files in Resources folder\n",
    "\n",
    "Running the following cell will extract the data zip files in the Resources folder, which contains the csv files needed for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell will unzip the data files in the Resources folder.\n",
    "extension = \".zip\"\n",
    "extracted_dir_name = \".\"\n",
    "\n",
    "# Get the current working directory.\n",
    "# Need to be in the root directory of this project for this to work.\n",
    "cwd_dir_name = os.getcwd()\n",
    "print(f\"The current working directory is {cwd_dir_name}.\")\n",
    "\n",
    "os.chdir(\"Resources\") # change directory from working dir to dir with the zip file(s) .\n",
    "# This should be the \"Resources\" folder.\n",
    "dir_name = os.getcwd()\n",
    "print(f\"You are now in the following directory: {dir_name}.\")\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through the items in the directory.\n",
    "    if item.endswith(extension): # check for \".zip\" extension\"\n",
    "        try:\n",
    "            file_name = os.path.abspath(item) # get full path of files\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            unzipped_directory = os.path.join(extracted_dir_name) # reference to the directory where the zip files will be extracted.\n",
    "            zip_ref.extractall(unzipped_directory) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            print(f\"Successfully unzipped {item} into the following folder:{dir_name}.\")\n",
    "        except:\n",
    "            print(f\"Error trying to unzip data file(s).\")\n",
    "            print(f\"Make sure that the files are closed and you have the correct file/folder permissions.\")\n",
    "            \n",
    "# Go up one directory into the project root directory.\n",
    "os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n",
    "print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store commodity csv into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_df = pd.read_csv(COMMODITY_TRADE_CSV, low_memory=False, encoding =\"utf-8\")\n",
    "\n",
    "commodity_trade_df.to_hdf('commodity_trade.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found out this read_hsf is faster than read_csv when working with really large datasets.\n",
    "commodity_trade_df = pd.read_hdf('commodity_trade.h5', 'df')\n",
    "\n",
    "commodity_trade_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns for commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_renamed_columns = commodity_trade_df.rename(columns={\n",
    "    \"comm_code\": \"commodity_code\",\n",
    "    \"commodity\": \"commodity_description\",\n",
    "    \"flow\": \"trade_flow\",\n",
    "    \"trade_usd\": \"trade_value_usd\",  \n",
    "})\n",
    "\n",
    "commodity_trade_renamed_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop null values from commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_no_null = commodity_trade_renamed_columns.dropna(how=\"any\")\n",
    "\n",
    "commodity_trade_no_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify commodity dataframe count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_no_null.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add auto incrementing id column to commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_no_null.insert(0, 'id', range(0, 0 + len(commodity_trade_no_null)))\n",
    "\n",
    "commodity_trade_no_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new category dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new category data frame with split value columns. \n",
    "category_df = commodity_trade_no_null[\"category\"].str.split(\"_\", n = 1, expand = True) \n",
    "  \n",
    "# Make separate category_id column from new category data frame.\n",
    "commodity_trade_no_null[\"category_id\"]= category_df[0] \n",
    "  \n",
    "# Dropping old category column. \n",
    "commodity_trade_no_null.drop(columns =[\"category\"], inplace = True) \n",
    "\n",
    "commodity_trade_no_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be something more meaningful.\n",
    "category_df = category_df.rename(columns={\n",
    "    0: \"category_id\",\n",
    "    1: \"category_name\"\n",
    "})\n",
    "\n",
    "# Drop duplicate categories.\n",
    "category_df.drop_duplicates(\"category_id\", inplace=True)\n",
    "\n",
    "category_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new commodity codes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new commodity codes dataframe that contains commodity code and commodity description columns.\n",
    "commodity_codes_df = commodity_trade_no_null.loc[:,[\"commodity_code\", \"commodity_description\"]]\n",
    "\n",
    "# Drop duplicate codes\n",
    "commodity_codes_df.drop_duplicates(\"commodity_code\", inplace=True)\n",
    "\n",
    "# Drop nulls\n",
    "commodity_codes_df.dropna(how=\"any\", inplace=True)\n",
    "\n",
    "commodity_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commodity_description column from previous dataframe.\n",
    "del commodity_trade_no_null[\"commodity_description\"]\n",
    "\n",
    "commodity_trade_no_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new countries dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new countries dataframe that contains country name and unique id columns.\n",
    "countries_df = commodity_trade_no_null.loc[:,[\"country_or_area\"]]\n",
    "\n",
    "# Drop duplicate codes\n",
    "countries_df.drop_duplicates(\"country_or_area\", inplace=True)\n",
    "\n",
    "# Drop nulls\n",
    "countries_df.dropna(how=\"any\", inplace=True)\n",
    "\n",
    "countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add auto-incrementing id column to countries dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df.insert(0, 'id', range(0, 0 + len(countries_df)))\n",
    "\n",
    "countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge countries dataframe with commodity dataframe on country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on country name using pandas.\n",
    "countries_commodities_merged = pd.merge(commodity_trade_no_null, countries_df, on=\"country_or_area\", how=\"outer\")\n",
    "\n",
    "# Rename columns\n",
    "countries_commodities_merged = countries_commodities_merged.rename(columns={\n",
    "    \"id_y\": \"country_id\",\n",
    "    \"id_x\": \"id\"\n",
    "})\n",
    "\n",
    "# Drop country name column.\n",
    "del countries_commodities_merged[\"country_or_area\"]\n",
    "\n",
    "countries_commodities_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_connection_string = f\"{username}:{password}@localhost:5432/{DB_NAME}\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classes/schemas that will be associated with tables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets an object to utilize the default declarative base in SQL Alchemy.\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classes and define schemas for different tables\n",
    "class CommodityCategory(Base):\n",
    "    __tablename__ = COMMODITY_CATEGORY_TABLE\n",
    "    category_id = Column(String(255), primary_key=True, nullable=False)\n",
    "    category_name = Column(String(255), nullable=False)\n",
    "    \n",
    "class CommodityCode(Base):\n",
    "    __tablename__ = COMMODITY_CODE_TABLE\n",
    "    commodity_code = Column(String(255), primary_key=True, nullable=False)\n",
    "    commodity_description = Column(String(255), nullable=True)\n",
    "    \n",
    "class Country(Base):\n",
    "    __tablename__ = COUNTRY_TABLE\n",
    "    id = Column(Integer, primary_key=True, nullable=False)\n",
    "    country_or_area = Column(String(255), nullable=False)\n",
    "\n",
    "class CommodityTrade(Base):\n",
    "    __tablename__ = COMMODITY_TABLE\n",
    "    id = Column(Integer, primary_key=True, nullable=False)\n",
    "    year = Column(Integer, nullable=False)\n",
    "    comodity_code = Column(String(255), ForeignKey(f\"{COMMODITY_CODE_TABLE}.commodity_code\"), nullable=False)\n",
    "    trade_flow = Column(String(255), nullable=False)\n",
    "    trade_value_usd = Column(String(255), nullable=False)\n",
    "    weight_kg = Column(Float, nullable=False)\n",
    "    quantity_name = Column(String(255), nullable=False)\n",
    "    quantity = Column(Float, nullable=False)\n",
    "    category_id = Column(String(255), ForeignKey(f\"{COMMODITY_CATEGORY_TABLE}.category_id\"), nullable=False)\n",
    "    country_id = Column(Integer, ForeignKey(f\"{COUNTRY_TABLE}.id\"), nullable=False)\n",
    "\n",
    "# Create (if not already in existence) the table associated with class.\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pandas to load commodity dataframe into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesnt work yet...\n",
    "# start_time = time.time()\n",
    "# d6tstack.utils.pd_to_psql(commodity_trade_no_null, cfg_uri_psql, COMMODITY_TABLE, if_exists='append',sep='\\t')\n",
    "# print(\"Time to load commodity dataframe into sql:\")\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pandas to load commodity category dataframe into sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d6tstack.utils.pd_to_psql(category_df, cfg_uri_psql, COMMODITY_CATEGORY_TABLE, if_exists='append')\n",
    "print(\"Time to load category dataframe into sql:\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pandas to load commodity codes dataframe into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't work yet...\n",
    "# start_time = time.time()\n",
    "# d6tstack.utils.pd_to_psql(commodity_codes_df, cfg_uri_psql, COMMODITY_CODE_TABLE, if_exists='append', sep='\\t')\n",
    "# print(\"Time to load codes dataframe into sql:\")\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pandas to load country dataframe into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d6tstack.utils.pd_to_psql(countries_df, cfg_uri_psql, COUNTRY_TABLE, if_exists='append', sep='\\t')\n",
    "print(\"Time to load country dataframe into sql:\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create session object to connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm category data has been added by querying the commedity category table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = session.query(CommodityCategory).limit(10)\n",
    "for category in category_list:\n",
    "    print(f\"id: {category.category_id}, category name: {category.category_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm country data has been added by quering the country table.\n",
    "country_list = session.query(Country).limit(10)\n",
    "for country in country_list:\n",
    "    print(f\"id: {country.id}, country name: {country.country_or_area}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phils Section End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connors Section Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#       DO NOT RUN ##########\n",
    "#############################\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database credentials\n",
    "from config import username, password\n",
    "\n",
    "# Used for making database connection.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "# Used to abstract classes into tables.\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "# Used to declare column types.\n",
    "from sqlalchemy import Column, Integer, String, Float, ForeignKey\n",
    "\n",
    "# Used to load pandas dataframe into sql.\n",
    "import d6tstack.utils\n",
    "import time\n",
    "\n",
    "# Ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Used for reading, writing to, and zipping files/folders.\n",
    "from pathlib import Path\n",
    "import os, zipfile\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#       DO NOT RUN ##########\n",
    "#############################\n",
    "# Constants\n",
    "COMMODITY_TRADE_CSV = os.path.join(\".\", \"Resources\", \"commodity_trade_statistics_data.csv\")\n",
    "FINANCIAL_AID_CSV =  os.path.join(\".\", \"Resources\", \"june-9-data-csv-1.csv\")\n",
    "DB_NAME = \"trade_db\"\n",
    "COMMODITY_TABLE = \"commodity\"\n",
    "COMMODITY_CATEGORY_TABLE = \"commodity_category\"\n",
    "COMMODITY_CODE_TABLE = \"commodity_code\"\n",
    "cfg_uri_psql = f\"postgresql+psycopg2://{username}:{password}@localhost/{DB_NAME}\"\n",
    "FINANCIAL_AID_TABLE = 'financial_aid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell will unzip the data files in the Resources folder.\n",
    "extension = \".zip\"\n",
    "extracted_dir_name = \".\"\n",
    "\n",
    "# Get the current working directory.\n",
    "# Need to be in the root directory of this project for this to work.\n",
    "cwd_dir_name = os.getcwd()\n",
    "print(f\"The current working directory is {cwd_dir_name}.\")\n",
    "\n",
    "os.chdir(\"Resources\") # change directory from working dir to dir with the zip file(s) .\n",
    "# This should be the \"Resources\" folder.\n",
    "dir_name = os.getcwd()\n",
    "print(f\"You are now in the following directory: {dir_name}.\")\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through the items in the directory.\n",
    "    if item.endswith(extension): # check for \".zip\" extension\"\n",
    "        try:\n",
    "            file_name = os.path.abspath(item) # get full path of files\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            unzipped_directory = os.path.join(extracted_dir_name) # reference to the directory where the zip files will be extracted.\n",
    "            zip_ref.extractall(unzipped_directory) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            print(f\"Successfully unzipped {item} into the following folder:{dir_name}.\")\n",
    "        except:\n",
    "            print(f\"Error trying to unzip data file(s).\")\n",
    "            print(f\"Make sure that the files are closed and you have the correct file/folder permissions.\")\n",
    "            \n",
    "# Go up one directory into the project root directory.\n",
    "os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n",
    "print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df = pd.read_csv(FINANCIAL_AID_CSV)\n",
    "financial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_financial_df = financial_df[['Donor Country','Donor Type','Aid Type','Receiver','Amount','Currency','USD Amount']]\n",
    "cleaned_financial_df = cleaned_financial_df.dropna()\n",
    "cleaned_financial_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_cleaned_financial_df = cleaned_financial_df.rename(columns={\n",
    "                                                     'Donor Country': 'donor_country',\n",
    "                                                     'Donor Type': 'donor_type',\n",
    "                                                     'Aid Type': 'aid_type',\n",
    "                                                     'Receiver': 'receiver',\n",
    "                                                     'Amount': 'amount',\n",
    "                                                     'Currency': 'currency',\n",
    "                                                     'USD Amount': 'USD_amount'})\n",
    "\n",
    "rn_cleaned_financial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_cleaned_financial_df.donor_country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping bad values\n",
    "rn_cleaned_financial_df = rn_cleaned_financial_df.drop(rn_cleaned_financial_df[rn_cleaned_financial_df.donor_country.isin(['Not Applicable\\r\\n','Not Applicable','Not Known'])].index)\n",
    "\n",
    "rn_cleaned_financial_df.donor_country.unique()\n",
    "sorted_df = combined_cleaned_df.sort_values(by='donor_country')\n",
    "sorted_df.donor_country.unique()\n",
    "sorted_df.to_excel('connor.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cleaned_df = rn_cleaned_financial_df.replace({\n",
    "    'HOLY SEE (VATICAN CITY STATE)':'Italy',\n",
    "    'Korea, Republic of': 'Rep. of Korea',\n",
    "    'TAIWAN, PROVINCE OF CHINA': 'China',\n",
    "    'CANADA': 'Canada',\n",
    "    'Baharain': 'Bahrain',\n",
    "    'Czech Republic': 'Czech Rep.',\n",
    "    'Monaco': 'Morocco',\n",
    "    'United States': 'USA',\n",
    "    'Hong Kong': 'China'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df.country_or_area.unique()\n",
    "countries_df.to_excel('phil.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cleaned_df.insert(0, 'id', range(0, 0 + len(combined_cleaned_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cleaned_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_w_country_id = pd.merge(combined_cleaned_df,countries_df,how='inner',left_on='donor_country',right_on='country_or_area')\n",
    "combined_w_country_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_w_country_id = combined_w_country_id.rename(columns={'id': 'country_id'})\n",
    "#del combined_w_country_id['donor_country']\n",
    "#del combined_w_country_id['country_or_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_w_country_id.insert(0, 'id', range(0, 0 + len(combined_w_country_id)))\n",
    "combined_w_country_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AidCategory.__table__.drop()\n",
    "\n",
    "class AidCategory(Base):\n",
    "    __tablename__ = FINANCIAL_AID_TABLE\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    donor_type = Column(String(255))\n",
    "    aid_type = Column(String(255))\n",
    "    receiver = Column(String(255))\n",
    "    amount = Column(Integer)\n",
    "    currency = Column(String(255))\n",
    "    USD_amount = Column(Integer)\n",
    "    country_id = Column(Integer, ForeignKey(f\"{COUNTRY_TABLE}.id\"), nullable=False)\n",
    "    \n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time.time()\n",
    "#d6tstack.utils.pd_to_psql(combined_w_country_id, cfg_uri_psql, FINANCIAL_AID_TABLE, if_exists='append', sep='\\t')\n",
    "#print(\"Time to load aid dataframe into sql:\")\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connors Section End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
