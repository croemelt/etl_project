{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phils Section Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL (Extract-Transform-Load) Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "* Run the following cell to import the necessary packages to run through this etl.\n",
    "* The only external package is **d6tstack**. So, you will need to install this in your virtual environment.\n",
    "  * For more information on this package and how to install it, see <https://pypi.org/project/d6tstack/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database credentials\n",
    "from config import username, password\n",
    "\n",
    "# Used for making database connection.\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.engine import reflection\n",
    "from sqlalchemy.schema import (\n",
    "        MetaData,\n",
    "        Table,\n",
    "        DropTable,\n",
    "        ForeignKeyConstraint,\n",
    "        DropConstraint,\n",
    "        )\n",
    "\n",
    "# Used to abstract classes into tables.\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "\n",
    "# Used to declare column types.\n",
    "from sqlalchemy import Column, Integer, String, Float, ForeignKey\n",
    "\n",
    "# Used to load pandas dataframe into sql.\n",
    "import d6tstack.utils\n",
    "import time\n",
    "\n",
    "# Ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Used for reading, writing to, and zipping files/folders.\n",
    "from pathlib import Path\n",
    "import os, zipfile\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "These are variables for items in this notebook that never change, such as csv file names, table names, database name, database connection string, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data csv files\n",
    "COMMODITY_TRADE_CSV = os.path.join(\".\", \"Resources\", \"commodity_trade_statistics_data.csv\")\n",
    "FINANCIAL_AID_CSV =  os.path.join(\".\", \"Resources\", \"june-9-data-csv-1.csv\")\n",
    "COMMODITY_CODES_CSV = os.path.join(\".\", \"Resources\", \"un_comtrade_commodity_classifications.csv\")\n",
    "\n",
    "# Database/tables\n",
    "DB_NAME = \"trade_db\"\n",
    "COMMODITY_TABLE = \"commodity\"\n",
    "COMMODITY_CATEGORY_TABLE = \"commodity_category\"\n",
    "COMMODITY_CODE_TABLE = \"commodity_code\"\n",
    "COUNTRY_TABLE = \"country\"\n",
    "FINANCIAL_AID_TABLE = 'financial_aid'\n",
    "COMMODITY_EXPORTS_TABLE = 'commodity_exports'\n",
    "COMMODITY_IMPORTS_TABLE = 'commodity_imports'\n",
    "\n",
    "# Database connection string for loading data into database.\n",
    "cfg_uri_psql = f\"postgresql+psycopg2://{username}:{password}@localhost/{DB_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip data files into the Resources folder\n",
    "\n",
    "* Before running this cell, create a folder in the project root directory (the same directory as this notebook) called **Resources**.\n",
    "* Then, manually download the data zip files from the team google drive folder and place inside the **Resources** folder you just created.\n",
    "* After that, you can run this cell. Running the following cell will extract the data zip files into the **Resources** folder you created, which will contain the csv files needed for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell will unzip the data files in the Resources folder.\n",
    "extension = \".zip\"\n",
    "extracted_dir_name = \".\"\n",
    "\n",
    "# Get the current working directory.\n",
    "# Need to be in the root directory of this project for this to work.\n",
    "cwd_dir_name = os.getcwd()\n",
    "print(f\"The current working directory is {cwd_dir_name}.\")\n",
    "\n",
    "os.chdir(\"Resources\") # change directory from working dir to dir with the zip file(s) .\n",
    "# This should be the \"Resources\" folder.\n",
    "dir_name = os.getcwd()\n",
    "print(f\"You are now in the following directory: {dir_name}.\")\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through the items in the directory.\n",
    "    if item.endswith(extension): # check for \".zip\" extension\"\n",
    "        try:\n",
    "            file_name = os.path.abspath(item) # get full path of files\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            unzipped_directory = os.path.join(extracted_dir_name) # reference to the directory where the zip files will be extracted.\n",
    "            zip_ref.extractall(unzipped_directory) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            print(f\"Successfully unzipped {item} into the following folder:{dir_name}.\")\n",
    "        except:\n",
    "            print(f\"Error trying to unzip data file(s).\")\n",
    "            print(f\"Make sure that the files are closed and you have the correct file/folder permissions.\")\n",
    "            \n",
    "# Go up one directory into the project root directory.\n",
    "os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n",
    "print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store commodity csv into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_df = pd.read_csv(COMMODITY_TRADE_CSV, low_memory=False, encoding =\"utf-8\")\n",
    "\n",
    "commodity_trade_df.to_hdf('commodity_trade.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found out this read_hsf is faster than read_csv when working with really large datasets.\n",
    "commodity_trade_df = pd.read_hdf('commodity_trade.h5', 'df')\n",
    "\n",
    "commodity_trade_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_renamed_columns = commodity_trade_df.rename(columns={\n",
    "    \"comm_code\": \"commodity_code\",\n",
    "    \"commodity\": \"commodity_description\",\n",
    "    \"flow\": \"trade_flow\",\n",
    "    \"trade_usd\": \"trade_value_usd\",  \n",
    "})\n",
    "\n",
    "commodity_trade_renamed_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop null values from commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_no_null = commodity_trade_renamed_columns.dropna(how=\"any\")\n",
    "\n",
    "commodity_trade_no_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify commodity dataframe count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_no_null.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add auto incrementing id column to commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_trade_no_null.insert(0, 'id', range(0, 0 + len(commodity_trade_no_null)))\n",
    "\n",
    "commodity_trade_no_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new category dataframe from the commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new category data frame with split value columns. \n",
    "category_df = commodity_trade_no_null[\"category\"].str.split(\"_\", n = 1, expand = True) \n",
    "  \n",
    "# Make separate category_id column from new category data frame.\n",
    "commodity_trade_no_null[\"category_id\"]= category_df[0] \n",
    "  \n",
    "# Dropping old category column. \n",
    "commodity_trade_no_null.drop(columns =[\"category\"], inplace = True) \n",
    "\n",
    "commodity_trade_no_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be something more meaningful.\n",
    "category_df = category_df.rename(columns={\n",
    "    0: \"category_id\",\n",
    "    1: \"category_name\"\n",
    "})\n",
    "\n",
    "# Drop duplicate categories.\n",
    "category_df.drop_duplicates(\"category_id\", inplace=True)\n",
    "\n",
    "category_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new commodity codes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new commodity codes dataframe that contains commodity code and commodity description columns.\n",
    "\n",
    "# Store commodity codes classification csv into pandas dataframe\n",
    "commodity_codes_df = pd.read_csv(COMMODITY_CODES_CSV, low_memory=False, encoding =\"utf-8\")\n",
    "\n",
    "commodity_codes_df.to_hdf('commodity_codes.h5', key='df', mode='w')\n",
    "\n",
    "# Found out this read_hsf is faster than read_csv when working with really large datasets.\n",
    "commodity_codes_df = pd.read_hdf('commodity_codes.h5', 'df')\n",
    "\n",
    "# Rename columns\n",
    "commodity_codes_df = commodity_codes_df.rename(columns={\n",
    "    \"Code\": \"commodity_code\",\n",
    "    \"Description\": \"commodity_description\"\n",
    "})\n",
    "\n",
    "# Drop duplicate codes\n",
    "commodity_codes_df.drop_duplicates(\"commodity_code\", inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "commodity_codes_df = commodity_codes_df[[\"commodity_code\", \"commodity_description\"]]\n",
    "\n",
    "commodity_codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify commodity codes dataframe count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_codes_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate commodity_description column from commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del commodity_trade_no_null[\"commodity_description\"]\n",
    "\n",
    "commodity_trade_no_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new countries dataframe from the commodity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new countries dataframe that contains country name and unique id columns.\n",
    "countries_df = commodity_trade_no_null.loc[:,[\"country_or_area\"]]\n",
    "\n",
    "# Drop duplicate codes\n",
    "countries_df.drop_duplicates(\"country_or_area\", inplace=True)\n",
    "\n",
    "# Drop nulls\n",
    "countries_df.dropna(how=\"any\", inplace=True)\n",
    "\n",
    "countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add auto-incrementing id column to countries dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df.insert(0, 'id', range(0, 0 + len(countries_df)))\n",
    "\n",
    "countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge countries dataframe with commodity dataframe on country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on country name using pandas.\n",
    "countries_commodities_merged = pd.merge(commodity_trade_no_null, countries_df, on=\"country_or_area\", how=\"outer\")\n",
    "\n",
    "# Rename columns\n",
    "countries_commodities_merged = countries_commodities_merged.rename(columns={\n",
    "    \"id_y\": \"country_id\",\n",
    "    \"id_x\": \"id\"\n",
    "})\n",
    "\n",
    "# Drop country name column.\n",
    "del countries_commodities_merged[\"country_or_area\"]\n",
    "\n",
    "countries_commodities_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split commodity dataframe into 2 dataframes based on trade flow - exports and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all possible values of trade_flow column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_commodities_merged[\"trade_flow\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataframe for commodity exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exports_df = countries_commodities_merged.loc[\n",
    "    (countries_commodities_merged[\"trade_flow\"] == \"Export\") | \n",
    "    (countries_commodities_merged[\"trade_flow\"] == \"Re-Export\")]\n",
    "\n",
    "exports_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataframe for commodity imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_df = countries_commodities_merged.loc[\n",
    "    (countries_commodities_merged[\"trade_flow\"] == \"Import\") | \n",
    "    (countries_commodities_merged[\"trade_flow\"] == \"Re-Import\")]\n",
    "\n",
    "imports_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_connection_string = f\"{username}:{password}@localhost:5432/{DB_NAME}\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANGEROUS: Drops everything in database\n",
    "\n",
    "Use with caution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_DropEverything(engine):\n",
    "    # From http://www.sqlalchemy.org/trac/wiki/UsageRecipes/DropEverything\n",
    "\n",
    "    conn = engine.connect()\n",
    "\n",
    "    trans = conn.begin()\n",
    "\n",
    "    inspector = inspect(engine)\n",
    "\n",
    "    metadata = MetaData()\n",
    "\n",
    "    tbs = []\n",
    "    all_fks = []\n",
    "\n",
    "    for table_name in inspector.get_table_names():\n",
    "        fks = []\n",
    "        for fk in inspector.get_foreign_keys(table_name):\n",
    "            if not fk['name']:\n",
    "                continue\n",
    "            fks.append(\n",
    "                ForeignKeyConstraint((),(),name=fk['name'])\n",
    "                )\n",
    "        t = Table(table_name,metadata,*fks)\n",
    "        tbs.append(t)\n",
    "        all_fks.extend(fks)\n",
    "\n",
    "    for fkc in all_fks:\n",
    "        conn.execute(DropConstraint(fkc))\n",
    "\n",
    "    for table in tbs:\n",
    "        conn.execute(DropTable(table))\n",
    "\n",
    "    trans.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_DropEverything(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classes/schemas that will be associated with tables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets an object to utilize the default declarative base in SQL Alchemy.\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out db\n",
    "Base.metadata.drop_all(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classes and define schemas for different tables\n",
    "class CommodityCategory(Base):\n",
    "    __tablename__ = COMMODITY_CATEGORY_TABLE\n",
    "    category_id = Column(String(255), primary_key=True, nullable=False, unique=True)\n",
    "    category_name = Column(String(255), nullable=False)\n",
    "    \n",
    "class CommodityCode(Base):\n",
    "    __tablename__ = COMMODITY_CODE_TABLE\n",
    "    commodity_code = Column(String(255), primary_key=True, nullable=False, unique=True)\n",
    "    commodity_description = Column(String(400), nullable=False)\n",
    "    \n",
    "class Country(Base):\n",
    "    __tablename__ = COUNTRY_TABLE\n",
    "    id = Column(Integer, primary_key=True, nullable=False, unique=True)\n",
    "    country_or_area = Column(String(255), nullable=False)\n",
    "\n",
    "class CommodityExports(Base):\n",
    "    __tablename__ = COMMODITY_EXPORTS_TABLE\n",
    "    id = Column(Integer, primary_key=True, nullable=False, unique=True)\n",
    "    year = Column(Integer, nullable=False)\n",
    "    comodity_code = Column(String(255), ForeignKey(f\"{COMMODITY_CODE_TABLE}.commodity_code\"), nullable=False)\n",
    "    trade_flow = Column(String(255), nullable=False)\n",
    "    trade_value_usd = Column(String(255), nullable=False)\n",
    "    weight_kg = Column(Float, nullable=False)\n",
    "    quantity_name = Column(String(255), nullable=False)\n",
    "    quantity = Column(Float, nullable=False)\n",
    "    category_id = Column(String(255), ForeignKey(f\"{COMMODITY_CATEGORY_TABLE}.category_id\"), nullable=False)\n",
    "    country_id = Column(Integer, ForeignKey(f\"{COUNTRY_TABLE}.id\"), nullable=False)\n",
    "    \n",
    "class CommodityImports(Base):\n",
    "    __tablename__ = COMMODITY_IMPORTS_TABLE\n",
    "    id = Column(Integer, primary_key=True, nullable=False, unique=True)\n",
    "    year = Column(Integer, nullable=False)\n",
    "    comodity_code = Column(String(255), ForeignKey(f\"{COMMODITY_CODE_TABLE}.commodity_code\"), nullable=False)\n",
    "    trade_flow = Column(String(255), nullable=False)\n",
    "    trade_value_usd = Column(String(255), nullable=False)\n",
    "    weight_kg = Column(Float, nullable=False)\n",
    "    quantity_name = Column(String(255), nullable=False)\n",
    "    quantity = Column(Float, nullable=False)\n",
    "    category_id = Column(String(255), ForeignKey(f\"{COMMODITY_CATEGORY_TABLE}.category_id\"), nullable=False)\n",
    "    country_id = Column(Integer, ForeignKey(f\"{COUNTRY_TABLE}.id\"), nullable=False)\n",
    "\n",
    "# Create (if not already in existence) the table associated with class.\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load final pandas dataframes into sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas/d6tstack to load commodity category dataframe into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d6tstack.utils.pd_to_psql(category_df, cfg_uri_psql, COMMODITY_CATEGORY_TABLE, if_exists='append')\n",
    "print(\"Time to load category dataframe into sql:\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas/d6tstack to load commodity codes dataframe into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d6tstack.utils.pd_to_psql(commodity_codes_df, cfg_uri_psql, COMMODITY_CODE_TABLE, if_exists='append', sep='\\t')\n",
    "print(\"Time to load codes dataframe into sql:\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas/d6tstack to load country dataframe into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d6tstack.utils.pd_to_psql(countries_df, cfg_uri_psql, COUNTRY_TABLE, if_exists='append', sep='\\t')\n",
    "print(\"Time to load country dataframe into sql:\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas/d6tstack to load commodity exports dataframe into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d6tstack.utils.pd_to_psql(exports_df, cfg_uri_psql, COMMODITY_EXPORTS_TABLE, if_exists='append',sep='\\t')\n",
    "print(\"Time to load commodity exports dataframe into sql:\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas/d6tstack to load commodity imports dataframe into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d6tstack.utils.pd_to_psql(imports_df, cfg_uri_psql, COMMODITY_IMPORTS_TABLE, if_exists='append',sep='\\t')\n",
    "print(\"Time to load commodity imports dataframe into sql:\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create session object to connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm data from pandas dataframes have been added to database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colllect the names of the tables within the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = inspect(engine)\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm category data has been added by querying the commedity category table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = session.query(CommodityCategory).limit(10)\n",
    "for category in category_list:\n",
    "    print(f\"id: {category.category_id}, category name: {category.category_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column names and types\n",
    "category_columns = inspector.get_columns(COMMODITY_CATEGORY_TABLE)\n",
    "for column in category_columns:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm country data has been added by querying the country table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = session.query(Country).limit(10)\n",
    "for country in country_list:\n",
    "    print(f\"id: {country.id}, country name: {country.country_or_area}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column names and types\n",
    "country_columns = inspector.get_columns(COUNTRY_TABLE)\n",
    "for column in country_columns:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm commodity codes data has been added by querying the commodity codes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_list = session.query(CommodityCode).limit(10)\n",
    "for code in codes_list:\n",
    "    print(f\"code: {code.commodity_code}, description: {code.commodity_description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column names and types\n",
    "code_columns = inspector.get_columns(COMMODITY_CODE_TABLE)\n",
    "for column in code_columns:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm commodity exports data has been added by querying the exports table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exports_list = session.query(CommodityExports).limit(10)\n",
    "for commodity in exports_list:\n",
    "    print(f\"commodity: {commodity.id}, trade flow: {commodity.trade_flow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column names and types\n",
    "exports_columns = inspector.get_columns(COMMODITY_EXPORTS_TABLE)\n",
    "for column in exports_columns:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm commodity imports data has been added by querying the imports table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_list = session.query(CommodityImports).limit(10)\n",
    "for commodity in imports_list:\n",
    "    print(f\"commodity: {commodity.id}, trade flow: {commodity.trade_flow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column names and types\n",
    "imports_columns = inspector.get_columns(COMMODITY_IMPORTS_TABLE)\n",
    "for column in imports_columns:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join tables in database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflect database into ORM classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE = Base.classes[COMMODITY_EXPORTS_TABLE]\n",
    "CO = Base.classes[COMMODITY_CODE_TABLE]\n",
    "CAT = Base.classes[COMMODITY_CATEGORY_TABLE]\n",
    "COU = Base.classes[COUNTRY_TABLE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join commodity exports table and country tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = [CE.id, CE.year, CE.trade_flow, CE.trade_value_usd, CE.weight_kg, CE.quantity_name, CE.quantity,\n",
    "      CE.country_id, CO.commodity_description, COU.country_or_area]\n",
    "query = session.query(*sel).filter(CE.country_id == COU.id).limit(10).all()\n",
    "\n",
    "\n",
    "for record in query:\n",
    "    (CE.id, CE.year, CE.trade_flow, CE.trade_value_usd, CE.weight_kg, CE.quantity_name, CE.quantity,\n",
    "     CE.country_id, CO.commodity_description, COU.country_or_area) = record\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phils Section End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connors Section Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#       DO NOT RUN ##########\n",
    "#############################\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database credentials\n",
    "from config import username, password\n",
    "\n",
    "# Used for making database connection.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "# Used to abstract classes into tables.\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "# Used to declare column types.\n",
    "from sqlalchemy import Column, Integer, String, Float, ForeignKey\n",
    "\n",
    "# Used to load pandas dataframe into sql.\n",
    "import d6tstack.utils\n",
    "import time\n",
    "\n",
    "# Ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Used for reading, writing to, and zipping files/folders.\n",
    "from pathlib import Path\n",
    "import os, zipfile\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#       DO NOT RUN ##########\n",
    "#############################\n",
    "# Constants\n",
    "COMMODITY_TRADE_CSV = os.path.join(\".\", \"Resources\", \"commodity_trade_statistics_data.csv\")\n",
    "FINANCIAL_AID_CSV =  os.path.join(\".\", \"Resources\", \"june-9-data-csv-1.csv\")\n",
    "DB_NAME = \"trade_db\"\n",
    "COMMODITY_TABLE = \"commodity\"\n",
    "COMMODITY_CATEGORY_TABLE = \"commodity_category\"\n",
    "COMMODITY_CODE_TABLE = \"commodity_code\"\n",
    "cfg_uri_psql = f\"postgresql+psycopg2://{username}:{password}@localhost/{DB_NAME}\"\n",
    "FINANCIAL_AID_TABLE = 'financial_aid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell will unzip the data files in the Resources folder.\n",
    "extension = \".zip\"\n",
    "extracted_dir_name = \".\"\n",
    "\n",
    "# Get the current working directory.\n",
    "# Need to be in the root directory of this project for this to work.\n",
    "cwd_dir_name = os.getcwd()\n",
    "print(f\"The current working directory is {cwd_dir_name}.\")\n",
    "\n",
    "os.chdir(\"Resources\") # change directory from working dir to dir with the zip file(s) .\n",
    "# This should be the \"Resources\" folder.\n",
    "dir_name = os.getcwd()\n",
    "print(f\"You are now in the following directory: {dir_name}.\")\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through the items in the directory.\n",
    "    if item.endswith(extension): # check for \".zip\" extension\"\n",
    "        try:\n",
    "            file_name = os.path.abspath(item) # get full path of files\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            unzipped_directory = os.path.join(extracted_dir_name) # reference to the directory where the zip files will be extracted.\n",
    "            zip_ref.extractall(unzipped_directory) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            print(f\"Successfully unzipped {item} into the following folder:{dir_name}.\")\n",
    "        except:\n",
    "            print(f\"Error trying to unzip data file(s).\")\n",
    "            print(f\"Make sure that the files are closed and you have the correct file/folder permissions.\")\n",
    "            \n",
    "# Go up one directory into the project root directory.\n",
    "os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n",
    "print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df = pd.read_csv(FINANCIAL_AID_CSV)\n",
    "financial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_financial_df = financial_df[['Donor Country','Donor Type','Aid Type','Receiver','Amount','Currency','USD Amount']]\n",
    "cleaned_financial_df = cleaned_financial_df.dropna()\n",
    "cleaned_financial_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_cleaned_financial_df = cleaned_financial_df.rename(columns={\n",
    "                                                     'Donor Country': 'donor_country',\n",
    "                                                     'Donor Type': 'donor_type',\n",
    "                                                     'Aid Type': 'aid_type',\n",
    "                                                     'Receiver': 'receiver',\n",
    "                                                     'Amount': 'amount',\n",
    "                                                     'Currency': 'currency',\n",
    "                                                     'USD Amount': 'USD_amount'})\n",
    "\n",
    "rn_cleaned_financial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_cleaned_financial_df.donor_country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping bad values\n",
    "rn_cleaned_financial_df = rn_cleaned_financial_df.drop(rn_cleaned_financial_df[rn_cleaned_financial_df.donor_country.isin(['Not Applicable\\r\\n','Not Applicable','Not Known'])].index)\n",
    "\n",
    "rn_cleaned_financial_df.donor_country.unique()\n",
    "sorted_df = combined_cleaned_df.sort_values(by='donor_country')\n",
    "sorted_df.donor_country.unique()\n",
    "sorted_df.to_excel('connor.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cleaned_df = rn_cleaned_financial_df.replace({\n",
    "    'HOLY SEE (VATICAN CITY STATE)':'Italy',\n",
    "    'Korea, Republic of': 'Rep. of Korea',\n",
    "    'TAIWAN, PROVINCE OF CHINA': 'China',\n",
    "    'CANADA': 'Canada',\n",
    "    'Baharain': 'Bahrain',\n",
    "    'Czech Republic': 'Czech Rep.',\n",
    "    'Monaco': 'Morocco',\n",
    "    'United States': 'USA',\n",
    "    'Hong Kong': 'China'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df.country_or_area.unique()\n",
    "countries_df.to_excel('phil.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cleaned_df.insert(0, 'id', range(0, 0 + len(combined_cleaned_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cleaned_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_w_country_id = pd.merge(combined_cleaned_df,countries_df,how='inner',left_on='donor_country',right_on='country_or_area')\n",
    "combined_w_country_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_w_country_id = combined_w_country_id.rename(columns={'id': 'country_id'})\n",
    "#del combined_w_country_id['donor_country']\n",
    "#del combined_w_country_id['country_or_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_w_country_id.insert(0, 'id', range(0, 0 + len(combined_w_country_id)))\n",
    "combined_w_country_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AidCategory.__table__.drop()\n",
    "\n",
    "class AidCategory(Base):\n",
    "    __tablename__ = FINANCIAL_AID_TABLE\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    donor_type = Column(String(255))\n",
    "    aid_type = Column(String(255))\n",
    "    receiver = Column(String(255))\n",
    "    amount = Column(Integer)\n",
    "    currency = Column(String(255))\n",
    "    USD_amount = Column(Integer)\n",
    "    country_id = Column(Integer, ForeignKey(f\"{COUNTRY_TABLE}.id\"), nullable=False)\n",
    "    \n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time.time()\n",
    "#d6tstack.utils.pd_to_psql(combined_w_country_id, cfg_uri_psql, FINANCIAL_AID_TABLE, if_exists='append', sep='\\t')\n",
    "#print(\"Time to load aid dataframe into sql:\")\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connors Section End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
